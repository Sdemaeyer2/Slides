---
title: "GKN 2020-2021: Contactmoment 6"
subtitle: "Logistische regressie-analyse (2)"
author: "Tine van Daal & Sofie Vermeiren"
date: 
fontsize: 10pt
always_allow_html: yes
output: 
  beamer_presentation:
    keep_tex: yes
    toc: yes
    slide_level: 2
    includes:
      in_header: edubron-beamer-header-simple.txt
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, tidy = TRUE)
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\\", options$size,"\n\n", x, "\n\n \\normalsize"), x)})
```

```{r ,warning=F,message=F,echo=F}
setwd("~/Documents/Onderwijs/GKN/2020-2021/Presentaties/C6")
library(dplyr)
library(knitr)
library(tidyr)
library(purrr)
library(ggplot2)
library(sjPlot)
library(lme4)
library(lmerTest)
load("Vlaanderen_1_2_3.RData")
source("OLP2 Functies.R")
library(car)
Vlaanderen_1_2_3$Onderpresteren <- recode(Vlaanderen_1_2_3$ASRIBM01,'1=1;2=1;3=0;4=0;5=0')
Vlaanderen_1_2_3$Gender <- recode(Vlaanderen_1_2_3$ASBG01, '1 = "Girls"; 2 = "Boys"') 
Vlaanderen_1_2_3$Ouders_GraagLezenZ <- scale(Vlaanderen_1_2_3$ASBHPLR) 
M1_PIRLS <- glm(Onderpresteren ~ Gender + Ouders_GraagLezenZ, 
                data = Vlaanderen_1_2_3, family = binomial())
```

```{r}
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}
```

# Recap

##

\textcolor{uarood}{Recap}

## Laatste model vorig contactmoment

```{r ,warning=F,message=F,echo=F,size="tiny", tidy="tidy", tidy.opts=list(width.cutoff=50), comment=""}
summary(M1_PIRLS)
```


## Effect van 'Ouders_GraagLezenZ'

\begincols
  \begincol{.48\textwidth}
\begin{center}
\includegraphics[width=0.95\textwidth]{PlotLOG.png}
\end{center}
\endcol
  \begincol{.48\textwidth}
  \begin{center}
\includegraphics[width=0.95\textwidth]{PlotPROB.png}
\end{center}
\endcol
\endcols

## Effect van 'Gender'

```{r, echo = T, out.height = "70%", warning = F, message = F, error = F, size = "tiny",tidy="tidy", tidy.opts=list(width.cutoff=50), comment=""}
library(sjPlot)
plot_model(M1_PIRLS, transform = NULL, type = "eff", terms = c("Gender"))
```

## Beide effecten samen?

```{r, echo = T, out.height = "70%", warning = F, message = F, error = F, size = "tiny", tidy="tidy", tidy.opts=list(width.cutoff=50), comment=""}
plot_model(M1_PIRLS, transform = NULL, type = "eff", terms = c("Ouders_GraagLezenZ", "Gender"))
```

# Odds

##

\textcolor{uarood}{Let's talk in Odds}


## Parameters als Odds interpreteren (1)

$$Logit(Onderpr. = 1 ) = $$
$$-1.376 +
  (-0.254*GenderGirl) + (-0.394*OudersLezenZ)  $$

```{r, echo = T, size = "tiny", comment=""}
exp(-1.376)
```

*Voor jongens wiens ouders gemiddeld graag lezen is de kans om te behoren tot de onderpresteerders 0.25 keer groter (of 1/0.25 = 4 keer kleiner) dan de kans om niet tot de onderpresteerders te behoren*

## Parameters als Odds interpreteren (2)

$$ Logit(Onderpr. = 1 ) =$$
$$-1.376 + (-0.254*GenderGirl) + (-0.394*OudersLezenZ) $$


```{r, echo = T, size = "tiny", comment=""}
exp(-0.254)
1/exp(-0.254)
```

*Voor meisjes wiens ouders gemiddeld graag lezen is de \textcolor{uarood}{kansverhouding} om te behoren tot de onderpresteerders eerder dan tot de 'niet onderpresteerders' 0.776 keer groter (of 1/0.776 = 1.289 keer kleiner) dan voor jongens*

\bigskip

0.776 is een **\textcolor{uarood}{Odds Ratio}**

## Parameters als Odds interpreteren (3)

\begin{center}
\includegraphics[width=0.75\textwidth]{LogOdds.png}
\end{center}

\bigskip
Voorspelde Odds voor meisjes:

```{r, echo = T, size = "tiny", comment=""}
## Voorspelde Odds meisjes:
exp(-1.376) * exp(-0.254)
```
\bigskip    
Odds zijn \textbf{multiplicatief}


# Het ene model is het andere niet

##

\textcolor{uarood}{Hoe goed zijn modellen?}


## Geen $R^2$

Bij gewone regressie-analyse hebben we een geschat residu:

$$ Score_{i}= \beta_0 + \beta_1 * x_1 + \beta_2 * x_2 + ... + \epsilon_{ij}$$
\bigskip    
Gewone regressieanalyse: *Ordinary Least Squares* (OLS) schattingen     
Schattingen die de afstand van de regressielijn met de residuen minimaliseert!


## Maximum Likelihood

Bij logistische regressieanalyse hebben we geen geschat residu!

$$ Logit(X=1)= \beta_0 + \beta_1 * x_1 + \beta_2 * x_2 + ... $$
\bigskip    
Logistische regressieanalyse: \textcolor{uarood}{Maximum Likelihood} (ML) schattingen

## Maximum Likelihood

\bigskip
Likelihood = functie van parameterwaarden (gegeven de data)!

\bigskip
Doel: die combinatie van parameterwaarden waarvoor de Likelihood zo hoog mogelijk is (=Maximaal)

\bigskip
Hoe? 

- Likelihood wordt eerst log-getransformeerd 
- Via 'afgeleiden' van Log-likelihood functie parameterwaarden waarvoor de log-likelihood maximaal is

\bigskip
$\rightarrow$ Voor een model krijgen we ook een \textcolor{uarood}{Log-likelihood (LL)} waarde (= indicatie van FIT!)

## Modellen vergelijken

\bigskip
2 concurrerende modellen, welk model zou je weerhouden?

\bigskip
$\rightarrow$ Model met hoogste waarde voor LL!

## Nulmodel als start

Nulmodel = model zonder voorspellers

```{r ,warning=F,message=F,echo=T,size="tiny", tidy="tidy", tidy.opts=list(width.cutoff=50), comment=""}
M0_PIRLS <- glm(Onderpresteren ~ 1, 
                data = Vlaanderen_1_2_3, family = binomial())
summary(M0_PIRLS)
```

## Vergelijking met Model1

```{r ,warning=F,message=F,echo=T,size="tiny", comment=""}
logLik(M0_PIRLS)
logLik(M1_PIRLS)
```
\bigskip    
In onderzoek wordt -2 keer LL gehanteerd (= **-2LL** of **Deviance**)

```{r ,warning=F,message=F,echo=T,size="tiny", comment=""}
deviance(M0_PIRLS)
deviance(M1_PIRLS)
```

## Via anova()

```{r ,echo=T,size="tiny", eval = F, error=T, comment=""}
anova(M0_PIRLS , M1_PIRLS)
```

$\rightarrow$ `Error in anova.glmlist(c(list(object), dotargs), dispersion = dispersion, : models were not all fitted to the same size of dataset`

## Vergelijking modellen (invloed van 'missing values')

Modellen kunnen enkel vergeleken worden als ze geschat zijn op dezelfde dataset (en dus ook op evenveel observatie-eenheden)!

```{r, echo = T, error = F, comment=""}
nrow(M0_PIRLS$model)
nrow(M1_PIRLS$model)
```

$\rightarrow$ Nulmodel herschatten op enkel de 4635 observaties om model te kunnen vergelijken

## Vergelijking modellen

Missing values verwijderen:
```{r ,warning=F,message=F,echo=T,size="tiny", tidy="tidy", tidy.opts=list(width.cutoff=50), comment=""}
Dat_analyse <- na.omit( Vlaanderen_1_2_3[ , c("Onderpresteren", "Gender", "Ouders_GraagLezenZ")] )
```
\medskip    
Modellen herschatten:
```{r ,warning=F,message=F,echo=T,size="tiny", tidy="tidy", tidy.opts=list(width.cutoff=50), comment=""}
M0_PIRLS <- glm(Onderpresteren ~ 1, 
                data = Dat_analyse, family = binomial())

M1_PIRLS <- glm(Onderpresteren ~ Gender + Ouders_GraagLezenZ, 
                data = Dat_analyse, family = binomial())
```
\medskip
Modellen vergelijken:
```{r ,warning=F,message=F,echo=T,size="tiny", tidy="tidy", tidy.opts=list(width.cutoff=50), comment=""}
anova(M0_PIRLS , M1_PIRLS, test="Chi")
```

## Vergelijking modellen

Stappenplan:

- Nadenken over welke modellen je gaat schatten (gegeven je OV)
- Data-object maken zonder missings voor alle variabelen `na.omit()`
- Alternatieve modellen schatten op aangemaakt data-object
- Modellen vergelijken 
- Beste model weerhouden en **herschatten op je originele dataset**
- Interpretatie (Nadenken over tabellen en figuren)



